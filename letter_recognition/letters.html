---
title: "Letter Reecognition"
author: "Rihad Variawa"
date: '2019-04-08'
output: html_document
summary: 'Predict which letter a particular image corresponds to'
header:
  image: headers/lr.jpg
---



<p>One of the earliest applications of predictive analytics methods applied so far was to automatically recognize letters, which post office machines use to sort mail. In this analysis, I’ll build a model that uses statistics of images of four letters in the Roman alphabet – A, B, P, and R – to predict which letter a particular image corresponds to.</p>
<p>Note, that this is a multiclass classification problem. We have mostly focused on binary classification problems (e.g., predicting whether an individual voted or not, whether the Supreme Court will affirm or reverse a case, whether or not a person is at risk for a certain disease, etc.). In this problem, we have more than two classifications that are possible for each observation.</p>
<p>The file letters_ABPR.csv contains 3116 observations, each of which corresponds to a certain image of one of the four letters A, B, P and R. The images came from 20 different fonts, which were then randomly distorted to produce the final images; each such distorted image is represented as a collection of pixels, each of which is “on” or “off”.</p>
<p>For each such distorted image, we have available certain statistics of the image in terms of these pixels, as well as which of the four letters the image is. This data comes from the UCI ML Repository.</p>
<p>This dataset contains the following 17 variables:</p>
<ul>
<li>letter = the letter that the image corresponds to (A, B, P or R)</li>
<li>xbox = the horizontal position of where the smallest box covering the letter shape begins.</li>
<li>ybox = the vertical position of where the smallest box covering the letter shape begins.</li>
<li>width = the width of this smallest box.</li>
<li>height = the height of this smallest box.</li>
<li>onpix = the total number of “on” pixels in the character image</li>
<li>xbar = the mean horizontal position of all of the “on” pixels</li>
<li>ybar = the mean vertical position of all of the “on” pixels</li>
<li>x2bar = the mean squared horizontal position of all of the “on” pixels in the image</li>
<li>y2bar = the mean squared vertical position of all of the “on” pixels in the image</li>
<li>xybar = the mean of the product of the horizontal and vertical position of all of the “on” pixels in the image</li>
<li>x2ybar = the mean of the product of the squared horizontal position and the vertical position of all of the “on” pixels</li>
<li>xy2bar = the mean of the product of the horizontal position and the squared vertical position of all of the “on” pixels</li>
<li>xedge = the mean number of edges (the number of times an “off” pixel is followed by an “on” pixel, or the image boundary is hit) as the image is scanned from left to right, along the whole vertical length of the image</li>
<li>xedgeycor = the mean of the product of the number of horizontal edges at each vertical position and the vertical position</li>
<li>yedge = the mean number of edges as the images is scanned from top to bottom, along the whole horizontal length of the image</li>
<li>yedgexcor = the mean of the product of the number of vertical edges at each horizontal position and the horizontal position</li>
</ul>
<div id="load-the-dataset" class="section level3">
<h3>Load the dataset</h3>
<pre class="r"><code>letters &lt;- read.csv(&quot;letters_ABPR.csv&quot;)
summary(letters)</code></pre>
<pre><code>##  letter       xbox             ybox            width       
##  A:789   Min.   : 0.000   Min.   : 0.000   Min.   : 1.000  
##  B:766   1st Qu.: 3.000   1st Qu.: 5.000   1st Qu.: 4.000  
##  P:803   Median : 4.000   Median : 7.000   Median : 5.000  
##  R:758   Mean   : 3.915   Mean   : 7.051   Mean   : 5.186  
##          3rd Qu.: 5.000   3rd Qu.: 9.000   3rd Qu.: 6.000  
##          Max.   :13.000   Max.   :15.000   Max.   :11.000  
##      height           onpix             xbar             ybar       
##  Min.   : 0.000   Min.   : 0.000   Min.   : 3.000   Min.   : 0.000  
##  1st Qu.: 4.000   1st Qu.: 2.000   1st Qu.: 6.000   1st Qu.: 6.000  
##  Median : 6.000   Median : 4.000   Median : 7.000   Median : 7.000  
##  Mean   : 5.276   Mean   : 3.869   Mean   : 7.469   Mean   : 7.197  
##  3rd Qu.: 7.000   3rd Qu.: 5.000   3rd Qu.: 8.000   3rd Qu.: 9.000  
##  Max.   :12.000   Max.   :12.000   Max.   :14.000   Max.   :15.000  
##      x2bar            y2bar           xybar            x2ybar     
##  Min.   : 0.000   Min.   :0.000   Min.   : 3.000   Min.   : 0.00  
##  1st Qu.: 3.000   1st Qu.:2.000   1st Qu.: 7.000   1st Qu.: 3.00  
##  Median : 4.000   Median :4.000   Median : 8.000   Median : 5.00  
##  Mean   : 4.706   Mean   :3.903   Mean   : 8.491   Mean   : 4.52  
##  3rd Qu.: 6.000   3rd Qu.:5.000   3rd Qu.:10.000   3rd Qu.: 6.00  
##  Max.   :11.000   Max.   :8.000   Max.   :14.000   Max.   :10.00  
##      xy2bar           xedge          xedgeycor          yedge     
##  Min.   : 0.000   Min.   : 0.000   Min.   : 1.000   Min.   : 0.0  
##  1st Qu.: 6.000   1st Qu.: 2.000   1st Qu.: 7.000   1st Qu.: 3.0  
##  Median : 7.000   Median : 2.000   Median : 8.000   Median : 4.0  
##  Mean   : 6.711   Mean   : 2.913   Mean   : 7.763   Mean   : 4.6  
##  3rd Qu.: 8.000   3rd Qu.: 4.000   3rd Qu.: 9.000   3rd Qu.: 6.0  
##  Max.   :14.000   Max.   :10.000   Max.   :13.000   Max.   :12.0  
##    yedgexcor     
##  Min.   : 1.000  
##  1st Qu.: 7.000  
##  Median : 8.000  
##  Mean   : 8.418  
##  3rd Qu.:10.000  
##  Max.   :13.000</code></pre>
<pre class="r"><code>str(letters)</code></pre>
<pre><code>## &#39;data.frame&#39;:    3116 obs. of  17 variables:
##  $ letter   : Factor w/ 4 levels &quot;A&quot;,&quot;B&quot;,&quot;P&quot;,&quot;R&quot;: 2 1 4 2 3 4 4 1 3 3 ...
##  $ xbox     : int  4 1 5 5 3 8 2 3 8 6 ...
##  $ ybox     : int  2 1 9 9 6 10 6 7 14 10 ...
##  $ width    : int  5 3 5 7 4 8 4 5 7 8 ...
##  $ height   : int  4 2 7 7 4 6 4 5 8 8 ...
##  $ onpix    : int  4 1 6 10 2 6 3 3 4 7 ...
##  $ xbar     : int  8 8 6 9 4 7 6 12 5 8 ...
##  $ ybar     : int  7 2 11 8 14 7 7 2 10 5 ...
##  $ x2bar    : int  6 2 7 4 8 3 5 3 6 7 ...
##  $ y2bar    : int  6 2 3 4 1 5 5 2 3 5 ...
##  $ xybar    : int  7 8 7 6 11 8 6 10 12 7 ...
##  $ x2ybar   : int  6 2 3 8 6 4 5 2 5 6 ...
##  $ xy2bar   : int  6 8 9 6 3 8 7 9 4 6 ...
##  $ xedge    : int  2 1 2 6 0 6 3 2 4 3 ...
##  $ xedgeycor: int  8 6 7 11 10 6 7 6 10 9 ...
##  $ yedge    : int  7 2 5 8 4 7 5 3 4 8 ...
##  $ yedgexcor: int  10 7 11 7 8 7 8 8 8 9 ...</code></pre>
</div>
<div id="problem-1.1---predicting-b-or-not-b" class="section level3">
<h3>Problem 1.1 - Predicting B or not B</h3>
<p>Let’s warm up by attempting to predict just whether a letter is B or not. To begin, load the file letters_ABPR.csv into R, and call it letters. Then, create a new variable isB in the dataframe, which takes the value “TRUE” if the observation corresponds to the letter B, and “FALSE” if it does not.</p>
<pre class="r"><code>letters$isB &lt;- as.factor(letters$letter == &quot;B&quot;)</code></pre>
<p>Now, split the dataset into a training and testing set, putting 50% of the data in the training set. Set the seed to 1000 before making the split. The first argument to sample.split should be the dependent variable “letters$isB”. Remember that TRUE values from sample.split should go in the training set.</p>
<pre class="r"><code>library(caTools)
set.seed(1000)
lettersSplit = sample.split(letters$isB, SplitRatio = 0.5)
lettersTrain = subset(letters, lettersSplit == TRUE)
lettersTest = subset(letters, lettersSplit == FALSE)</code></pre>
<p>Before building models, let’s consider a baseline method that always predicts the most frequent outcome, which is “not B”.</p>
<p>What is the accuracy of this baseline method on the test set?</p>
<pre class="r"><code>table(letters$isB)</code></pre>
<pre><code>## 
## FALSE  TRUE 
##  2350   766</code></pre>
<pre class="r"><code>table(lettersTest$isB)</code></pre>
<pre><code>## 
## FALSE  TRUE 
##  1175   383</code></pre>
<pre class="r"><code>1175 / (1175 + 383)</code></pre>
<pre><code>## [1] 0.754172</code></pre>
</div>
<div id="problem-1.2---predicting-b-or-not-b" class="section level3">
<h3>Problem 1.2 - Predicting B or not B</h3>
<p>Now, build a classification tree to predict whether a letter is a B or not, using the training set to build the model. Remember to remove the variable “letter” out of the model, as this is related to what we are trying to predict!</p>
<pre class="r"><code>library(rpart)
library(rpart.plot)
CARTb &lt;- rpart(isB ~ . - letter, data = lettersTrain, method=&quot;class&quot;)</code></pre>
<p>We are just using the default parameters in our CART model, so we don’t need to add the minbucket or cp arguments at all. We also added the argument method=“class” since this is a classification problem.</p>
<p>What is the accuracy of the CART model on the test-set? (Use type=“class” when making predictions on the test set.)</p>
<pre class="r"><code>bPredict &lt;- predict(CARTb, newdata = lettersTest, type = &quot;class&quot;)
table(lettersTest$isB, bPredict)</code></pre>
<pre><code>##        bPredict
##         FALSE TRUE
##   FALSE  1118   57
##   TRUE     43  340</code></pre>
<pre class="r"><code>(1126 + 342) / nrow(lettersTest)</code></pre>
<pre><code>## [1] 0.9422336</code></pre>
</div>
<div id="problem-1.3---predicting-b-or-not-b" class="section level3">
<h3>Problem 1.3 - Predicting B or Not B</h3>
<p>Now, build a random forest model to predict whether the letter is a B or not (the isB variable) using the training set. Using all of the other variables as independent variables, except letter (since it helped us define what we are trying to predict!). Using the default settings for ntree and nodesize (don’t include these arguments at all). Right before building the model, set the seed to 1000. (NOTE: You might get a slightly different answer on this problem, even if you set the random seed. This has to do with your operating system and the implementation of the random forest algorithm.)</p>
<p>What is the accuracy of the model on the test set?</p>
<pre class="r"><code>bForestPredict &lt;- predict(bForest, newdata = lettersTest, type = &quot;class&quot;)
table(lettersTest$isB, bForestPredict)</code></pre>
<pre><code>##        bForestPredict
##         FALSE TRUE
##   FALSE  1163   12
##   TRUE      9  374</code></pre>
<pre class="r"><code>(1164 + 372) / nrow(lettersTest)</code></pre>
<pre><code>## [1] 0.9858793</code></pre>
<p>Random forests tends to improve on CART in terms of predictive accuracy. Sometimes, this improvement can be quite significant, as it is here.</p>
</div>
<div id="problem-2.1---predicting-the-letters-a-b-p-r" class="section level3">
<h3>Problem 2.1 - Predicting the letters A, B, P, R</h3>
<p>Let us now move on to the problem that we were originally interested in, which is to predict whether or not a letter is one of the four letters A, B, P or R.</p>
<p>As we saw earlier, building a multiclass classification CART model is no harder than building the models for binary classification problems. Fortunately, building a random forest model is just as easy. The variable in our dataframe which we will be trying to predict is “letter”.</p>
<p>Start by converting letter in the original dataset (letters) to a factor by running the following code:</p>
<pre class="r"><code>letters$letter &lt;- as.factor(letters$letter)</code></pre>
<p>Now, generate new training and testing sets of the letters dataframe using letters$letter as the first input to the sample.split function. Before splitting, set your seed to 2000. Again put 50% of the data in the training set. (Why do we need to split the data again? Remember that sample.split balances the outcome variable in the training and testing sets. With a new outcome variable, we want to re-generate our split.)</p>
<pre class="r"><code>set.seed(2000)
lettersAllSplit &lt;- sample.split(letters$letter, SplitRatio = 0.5)
lettersAllTrain &lt;- subset(letters, lettersAllSplit == TRUE)
lettersAllTest &lt;- subset(letters, lettersAllSplit == FALSE)</code></pre>
<p>In a multiclass classification problem, a simple baseline model is to predict the most frequent class of all of the options.</p>
<p>What is the baseline accuracy on the testing set?</p>
<pre class="r"><code>table(letters$letter)</code></pre>
<pre><code>## 
##   A   B   P   R 
## 789 766 803 758</code></pre>
<pre class="r"><code>table(lettersAllTest$letter)</code></pre>
<pre><code>## 
##   A   B   P   R 
## 395 383 401 379</code></pre>
<pre class="r"><code>401 / nrow(lettersAllTest)</code></pre>
<pre><code>## [1] 0.2573813</code></pre>
<div id="p-is-the-most-frequent-class-in-the-test-set" class="section level4">
<h4>P is the most frequent class in the test set</h4>
</div>
</div>
<div id="problem-2.2---predicting-the-letters-a-b-p-r" class="section level3">
<h3>Problem 2.2 - Predicting the letters A, B, P, R</h3>
<p>Now build a classification tree to predict “letter”, using the training set to build our model. You should use all of the other variables as independent variables, except “isB”, since it is related to what we are trying to predict!</p>
<p>Just use the default parameters in your CART model. Add the argument method=“class” since this is a classification problem. Even though we have multiple classes here, nothing changes in how we build the model from the binary case.</p>
<pre class="r"><code>CARTletters &lt;- rpart(letter ~ . - isB, data = lettersAllTrain, method=&quot;class&quot;)
summary(CARTletters)</code></pre>
<pre><code>## Call:
## rpart(formula = letter ~ . - isB, data = lettersAllTrain, method = &quot;class&quot;)
##   n= 1558 
## 
##           CP nsplit rel error    xerror       xstd
## 1 0.31920415      0 1.0000000 1.0346021 0.01442043
## 2 0.25865052      1 0.6807958 0.6323529 0.01704001
## 3 0.18685121      2 0.4221453 0.4238754 0.01585412
## 4 0.02595156      3 0.2352941 0.2370242 0.01299919
## 5 0.02076125      4 0.2093426 0.2162630 0.01253234
## 6 0.01730104      5 0.1885813 0.1980969 0.01209034
## 7 0.01384083      6 0.1712803 0.1894464 0.01186782
## 8 0.01211073      7 0.1574394 0.1678201 0.01127370
## 9 0.01000000      8 0.1453287 0.1608997 0.01107113
## 
## Variable importance
##      ybar xedgeycor    x2ybar    xy2bar     yedge     y2bar     xedge 
##        17        16        14        12        11         8         7 
##     xybar     x2bar      xbar 
##         5         5         3 
## 
## Node number 1: 1558 observations,    complexity param=0.3192042
##   predicted class=P  expected loss=0.7419769  P(node) =1
##     class counts:   394   383   402   379
##    probabilities: 0.253 0.246 0.258 0.243 
##   left son=2 (1088 obs) right son=3 (470 obs)
##   Primary splits:
##       xedgeycor &lt; 8.5  to the left,  improve=293.2010, (0 missing)
##       ybar      &lt; 5.5  to the left,  improve=287.8322, (0 missing)
##       xy2bar    &lt; 5.5  to the right, improve=278.1742, (0 missing)
##       x2ybar    &lt; 2.5  to the left,  improve=262.6356, (0 missing)
##       yedge     &lt; 4.5  to the left,  improve=177.0582, (0 missing)
##   Surrogate splits:
##       xy2bar &lt; 5.5  to the right, agree=0.892, adj=0.643, (0 split)
##       ybar   &lt; 8.5  to the left,  agree=0.821, adj=0.406, (0 split)
##       xedge  &lt; 1.5  to the right, agree=0.816, adj=0.391, (0 split)
##       xybar  &lt; 10.5 to the left,  agree=0.785, adj=0.287, (0 split)
##       x2ybar &lt; 6.5  to the left,  agree=0.777, adj=0.262, (0 split)
## 
## Node number 2: 1088 observations,    complexity param=0.2586505
##   predicted class=A  expected loss=0.6488971  P(node) =0.6983312
##     class counts:   382   338    13   355
##    probabilities: 0.351 0.311 0.012 0.326 
##   left son=4 (344 obs) right son=5 (744 obs)
##   Primary splits:
##       ybar      &lt; 5.5  to the left,  improve=275.7625, (0 missing)
##       x2ybar    &lt; 2.5  to the left,  improve=240.6702, (0 missing)
##       y2bar     &lt; 2.5  to the left,  improve=226.4519, (0 missing)
##       yedge     &lt; 3.5  to the left,  improve=215.2610, (0 missing)
##       xedgeycor &lt; 7.5  to the right, improve=171.4917, (0 missing)
##   Surrogate splits:
##       x2ybar &lt; 2.5  to the left,  agree=0.904, adj=0.698, (0 split)
##       y2bar  &lt; 2.5  to the left,  agree=0.892, adj=0.657, (0 split)
##       yedge  &lt; 3.5  to the left,  agree=0.881, adj=0.625, (0 split)
##       x2bar  &lt; 2.5  to the left,  agree=0.820, adj=0.430, (0 split)
##       xbar   &lt; 9.5  to the right, agree=0.779, adj=0.302, (0 split)
## 
## Node number 3: 470 observations,    complexity param=0.01730104
##   predicted class=P  expected loss=0.1723404  P(node) =0.3016688
##     class counts:    12    45   389    24
##    probabilities: 0.026 0.096 0.828 0.051 
##   left son=6 (91 obs) right son=7 (379 obs)
##   Primary splits:
##       xybar  &lt; 7.5  to the left,  improve=59.48719, (0 missing)
##       xy2bar &lt; 6.5  to the right, improve=54.86112, (0 missing)
##       ybar   &lt; 7.5  to the left,  improve=49.49367, (0 missing)
##       yedge  &lt; 6.5  to the right, improve=48.42295, (0 missing)
##       xedge  &lt; 5.5  to the left,  improve=30.83057, (0 missing)
##   Surrogate splits:
##       xy2bar &lt; 6.5  to the right, agree=0.936, adj=0.670, (0 split)
##       ybar   &lt; 7.5  to the left,  agree=0.902, adj=0.495, (0 split)
##       xedge  &lt; 5.5  to the right, agree=0.889, adj=0.429, (0 split)
##       yedge  &lt; 6.5  to the right, agree=0.885, adj=0.407, (0 split)
##       onpix  &lt; 6.5  to the right, agree=0.838, adj=0.165, (0 split)
## 
## Node number 4: 344 observations
##   predicted class=A  expected loss=0.04360465  P(node) =0.2207959
##     class counts:   329     9     3     3
##    probabilities: 0.956 0.026 0.009 0.009 
## 
## Node number 5: 744 observations,    complexity param=0.1868512
##   predicted class=R  expected loss=0.5268817  P(node) =0.4775353
##     class counts:    53   329    10   352
##    probabilities: 0.071 0.442 0.013 0.473 
##   left son=10 (342 obs) right son=11 (402 obs)
##   Primary splits:
##       xedgeycor &lt; 7.5  to the right, improve=139.70670, (0 missing)
##       xy2bar    &lt; 7.5  to the left,  improve= 92.43059, (0 missing)
##       x2ybar    &lt; 5.5  to the right, improve= 81.07422, (0 missing)
##       y2bar     &lt; 4.5  to the right, improve= 56.45671, (0 missing)
##       yedgexcor &lt; 10.5 to the left,  improve= 52.58754, (0 missing)
##   Surrogate splits:
##       x2ybar &lt; 5.5  to the right, agree=0.738, adj=0.430, (0 split)
##       xy2bar &lt; 6.5  to the left,  agree=0.675, adj=0.292, (0 split)
##       xedge  &lt; 2.5  to the left,  agree=0.675, adj=0.292, (0 split)
##       yedge  &lt; 5.5  to the right, agree=0.644, adj=0.225, (0 split)
##       ybar   &lt; 7.5  to the left,  agree=0.625, adj=0.184, (0 split)
## 
## Node number 6: 91 observations,    complexity param=0.01384083
##   predicted class=B  expected loss=0.5604396  P(node) =0.05840822
##     class counts:    10    40    20    21
##    probabilities: 0.110 0.440 0.220 0.231 
##   left son=12 (55 obs) right son=13 (36 obs)
##   Primary splits:
##       x2bar     &lt; 3.5  to the right, improve=14.308240, (0 missing)
##       xy2bar    &lt; 7.5  to the left,  improve= 9.472092, (0 missing)
##       yedge     &lt; 4.5  to the left,  improve= 9.449763, (0 missing)
##       x2ybar    &lt; 7.5  to the right, improve= 8.053076, (0 missing)
##       yedgexcor &lt; 6.5  to the right, improve= 7.478284, (0 missing)
##   Surrogate splits:
##       yedgexcor &lt; 5.5  to the right, agree=0.736, adj=0.333, (0 split)
##       x2ybar    &lt; 7.5  to the left,  agree=0.725, adj=0.306, (0 split)
##       yedge     &lt; 5.5  to the right, agree=0.725, adj=0.306, (0 split)
##       xy2bar    &lt; 8.5  to the left,  agree=0.714, adj=0.278, (0 split)
##       ybar      &lt; 7.5  to the left,  agree=0.681, adj=0.194, (0 split)
## 
## Node number 7: 379 observations
##   predicted class=P  expected loss=0.02638522  P(node) =0.2432606
##     class counts:     2     5   369     3
##    probabilities: 0.005 0.013 0.974 0.008 
## 
## Node number 10: 342 observations,    complexity param=0.02595156
##   predicted class=B  expected loss=0.2192982  P(node) =0.2195122
##     class counts:    14   267    10    51
##    probabilities: 0.041 0.781 0.029 0.149 
##   left son=20 (283 obs) right son=21 (59 obs)
##   Primary splits:
##       xy2bar    &lt; 7.5  to the left,  improve=48.65030, (0 missing)
##       xedge     &lt; 2.5  to the left,  improve=33.98799, (0 missing)
##       y2bar     &lt; 4.5  to the right, improve=27.13499, (0 missing)
##       yedgexcor &lt; 6.5  to the left,  improve=15.49245, (0 missing)
##       ybar      &lt; 8.5  to the left,  improve=15.03303, (0 missing)
##   Surrogate splits:
##       xedge     &lt; 5.5  to the left,  agree=0.871, adj=0.254, (0 split)
##       yedgexcor &lt; 4.5  to the right, agree=0.854, adj=0.153, (0 split)
##       ybar      &lt; 9.5  to the left,  agree=0.848, adj=0.119, (0 split)
##       xbox      &lt; 6.5  to the left,  agree=0.842, adj=0.085, (0 split)
##       ybox      &lt; 11.5 to the left,  agree=0.842, adj=0.085, (0 split)
## 
## Node number 11: 402 observations,    complexity param=0.02076125
##   predicted class=R  expected loss=0.2512438  P(node) =0.2580231
##     class counts:    39    62     0   301
##    probabilities: 0.097 0.154 0.000 0.749 
##   left son=22 (26 obs) right son=23 (376 obs)
##   Primary splits:
##       yedge     &lt; 2.5  to the left,  improve=35.46191, (0 missing)
##       x2ybar    &lt; 0.5  to the left,  improve=34.14932, (0 missing)
##       y2bar     &lt; 1.5  to the left,  improve=33.87850, (0 missing)
##       x2bar     &lt; 3.5  to the left,  improve=19.57685, (0 missing)
##       yedgexcor &lt; 8.5  to the left,  improve=19.07812, (0 missing)
##   Surrogate splits:
##       y2bar  &lt; 1.5  to the left,  agree=0.993, adj=0.885, (0 split)
##       x2ybar &lt; 0.5  to the left,  agree=0.993, adj=0.885, (0 split)
## 
## Node number 12: 55 observations
##   predicted class=B  expected loss=0.3090909  P(node) =0.03530167
##     class counts:     1    38    13     3
##    probabilities: 0.018 0.691 0.236 0.055 
## 
## Node number 13: 36 observations
##   predicted class=R  expected loss=0.5  P(node) =0.02310655
##     class counts:     9     2     7    18
##    probabilities: 0.250 0.056 0.194 0.500 
## 
## Node number 20: 283 observations
##   predicted class=B  expected loss=0.08480565  P(node) =0.1816431
##     class counts:     3   259     8    13
##    probabilities: 0.011 0.915 0.028 0.046 
## 
## Node number 21: 59 observations
##   predicted class=R  expected loss=0.3559322  P(node) =0.03786906
##     class counts:    11     8     2    38
##    probabilities: 0.186 0.136 0.034 0.644 
## 
## Node number 22: 26 observations
##   predicted class=A  expected loss=0.03846154  P(node) =0.01668806
##     class counts:    25     0     0     1
##    probabilities: 0.962 0.000 0.000 0.038 
## 
## Node number 23: 376 observations,    complexity param=0.01211073
##   predicted class=R  expected loss=0.2021277  P(node) =0.241335
##     class counts:    14    62     0   300
##    probabilities: 0.037 0.165 0.000 0.798 
##   left son=46 (26 obs) right son=47 (350 obs)
##   Primary splits:
##       yedge  &lt; 7.5  to the right, improve=19.73450, (0 missing)
##       x2ybar &lt; 5.5  to the right, improve=16.32647, (0 missing)
##       xybar  &lt; 8.5  to the right, improve=15.20779, (0 missing)
##       xedge  &lt; 3.5  to the right, improve=14.35240, (0 missing)
##       onpix  &lt; 4.5  to the right, improve=12.94437, (0 missing)
##   Surrogate splits:
##       xedgeycor &lt; 4.5  to the left,  agree=0.939, adj=0.115, (0 split)
## 
## Node number 46: 26 observations
##   predicted class=B  expected loss=0.3076923  P(node) =0.01668806
##     class counts:     4    18     0     4
##    probabilities: 0.154 0.692 0.000 0.154 
## 
## Node number 47: 350 observations
##   predicted class=R  expected loss=0.1542857  P(node) =0.224647
##     class counts:    10    44     0   296
##    probabilities: 0.029 0.126 0.000 0.846</code></pre>
<pre class="r"><code>prp(CARTletters)</code></pre>
<p><img src="/project/letter_recognition/letters_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>What is the test-set accuracy of our CART model? Use the argument type=“class” when making predictions. (HINT: When you are computing the test-set accuracy using the confusion matrix, you want to add everything on the main diagonal and divide by the total number of observations in the test-set, which can be computed with nrow(test), where test is the name of our test-set).</p>
<pre class="r"><code>lettersPredict &lt;- 
    as.vector(predict(CARTletters, newdata = lettersAllTest, type = &quot;class&quot;))
length(lettersPredict)</code></pre>
<pre><code>## [1] 1558</code></pre>
<pre class="r"><code>lettersPredict</code></pre>
<pre><code>##    [1] &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot;
##   [18] &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot;
##   [35] &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot;
##   [52] &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot;
##   [69] &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot;
##   [86] &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot;
##  [103] &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot;
##  [120] &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot;
##  [137] &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot;
##  [154] &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot;
##  [171] &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot;
##  [188] &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot;
##  [205] &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot;
##  [222] &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot;
##  [239] &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot;
##  [256] &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot;
##  [273] &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot;
##  [290] &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot;
##  [307] &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot;
##  [324] &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot;
##  [341] &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot;
##  [358] &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot;
##  [375] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot;
##  [392] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot;
##  [409] &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot;
##  [426] &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot;
##  [443] &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot;
##  [460] &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot;
##  [477] &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot;
##  [494] &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot;
##  [511] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot;
##  [528] &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot;
##  [545] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot;
##  [562] &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot;
##  [579] &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot;
##  [596] &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot;
##  [613] &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot;
##  [630] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot;
##  [647] &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot;
##  [664] &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot;
##  [681] &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot;
##  [698] &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot;
##  [715] &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot;
##  [732] &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot;
##  [749] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot;
##  [766] &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot;
##  [783] &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot;
##  [800] &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot;
##  [817] &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot;
##  [834] &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot;
##  [851] &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot;
##  [868] &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot;
##  [885] &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot;
##  [902] &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot;
##  [919] &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot;
##  [936] &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot;
##  [953] &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot;
##  [970] &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot;
##  [987] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot;
## [1004] &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot;
## [1021] &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot;
## [1038] &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot;
## [1055] &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot;
## [1072] &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot;
## [1089] &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot;
## [1106] &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot;
## [1123] &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot;
## [1140] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot;
## [1157] &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot;
## [1174] &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot;
## [1191] &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot;
## [1208] &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot;
## [1225] &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot;
## [1242] &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot;
## [1259] &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot;
## [1276] &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot;
## [1293] &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot;
## [1310] &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot;
## [1327] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot;
## [1344] &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot;
## [1361] &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot;
## [1378] &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot;
## [1395] &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot;
## [1412] &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot;
## [1429] &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot;
## [1446] &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot;
## [1463] &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot;
## [1480] &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot;
## [1497] &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot;
## [1514] &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot;
## [1531] &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot;
## [1548] &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot;</code></pre>
<pre class="r"><code>nrow(lettersAllTest)</code></pre>
<pre><code>## [1] 1558</code></pre>
<pre class="r"><code>table(lettersAllTest$letter, lettersPredict)</code></pre>
<pre><code>##    lettersPredict
##       A   B   P   R
##   A 348   4   0  43
##   B   8 318  12  45
##   P   2  21 363  15
##   R  10  24   5 340</code></pre>
<pre class="r"><code>(348 + 318 + 363 + 340) / nrow(lettersAllTest)</code></pre>
<pre><code>## [1] 0.8786906</code></pre>
</div>
<div id="problem-2.3---predicting-the-letters-a-b-p-r" class="section level3">
<h3>Problem 2.3 - Predicting the letters A, B, P, R</h3>
<p>Now build a random forest model on the training data, using the same independent variables as in the previous problem – again, don’t forget to remove the isB variable.</p>
<p>Just use the default parameter values for ntree and node size (you don’t need to include these arguments at all). Set the seed to 1000 right before building our model. (Remember that you might get a slightly different result even if you set the random seed.)</p>
<pre class="r"><code>set.seed(1000)
lettersForest &lt;- randomForest(letter ~ . - isB, data = lettersAllTrain)</code></pre>
<p>What is the test-set accuracy of your random forest model?</p>
<pre class="r"><code>lettersForestPredict &lt;- 
    as.vector(predict(lettersForest, newdata = lettersAllTest, type = &quot;class&quot;))
lettersForestPredict</code></pre>
<pre><code>##    [1] &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot;
##   [18] &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot;
##   [35] &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot;
##   [52] &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot;
##   [69] &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot;
##   [86] &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot;
##  [103] &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot;
##  [120] &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot;
##  [137] &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot;
##  [154] &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot;
##  [171] &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot;
##  [188] &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot;
##  [205] &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot;
##  [222] &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot;
##  [239] &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot;
##  [256] &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot;
##  [273] &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot;
##  [290] &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot;
##  [307] &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot;
##  [324] &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot;
##  [341] &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot;
##  [358] &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot;
##  [375] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot;
##  [392] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot;
##  [409] &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot;
##  [426] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot;
##  [443] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot;
##  [460] &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot;
##  [477] &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot;
##  [494] &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot;
##  [511] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot;
##  [528] &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot;
##  [545] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot;
##  [562] &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot;
##  [579] &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot;
##  [596] &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot;
##  [613] &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot;
##  [630] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot;
##  [647] &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot;
##  [664] &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot;
##  [681] &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot;
##  [698] &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot;
##  [715] &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot;
##  [732] &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot;
##  [749] &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot;
##  [766] &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot;
##  [783] &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot;
##  [800] &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot;
##  [817] &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot;
##  [834] &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot;
##  [851] &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot;
##  [868] &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot;
##  [885] &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot;
##  [902] &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot;
##  [919] &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot;
##  [936] &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot;
##  [953] &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot;
##  [970] &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot;
##  [987] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot;
## [1004] &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot;
## [1021] &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot;
## [1038] &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot;
## [1055] &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot;
## [1072] &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot;
## [1089] &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot;
## [1106] &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot;
## [1123] &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot;
## [1140] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot;
## [1157] &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot;
## [1174] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot;
## [1191] &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot;
## [1208] &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot;
## [1225] &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot;
## [1242] &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot;
## [1259] &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;A&quot;
## [1276] &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot;
## [1293] &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot;
## [1310] &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot;
## [1327] &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot;
## [1344] &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot;
## [1361] &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot;
## [1378] &quot;R&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot;
## [1395] &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot;
## [1412] &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot;
## [1429] &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot;
## [1446] &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot;
## [1463] &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot;
## [1480] &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot;
## [1497] &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;R&quot; &quot;R&quot;
## [1514] &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;R&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;P&quot;
## [1531] &quot;A&quot; &quot;R&quot; &quot;B&quot; &quot;B&quot; &quot;P&quot; &quot;R&quot; &quot;B&quot; &quot;R&quot; &quot;A&quot; &quot;P&quot; &quot;P&quot; &quot;P&quot; &quot;B&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;B&quot;
## [1548] &quot;P&quot; &quot;P&quot; &quot;A&quot; &quot;R&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;P&quot; &quot;R&quot; &quot;A&quot;</code></pre>
<pre class="r"><code>table(lettersAllTest$letter, lettersForestPredict)</code></pre>
<pre><code>##    lettersForestPredict
##       A   B   P   R
##   A 391   0   3   1
##   B   0 380   1   2
##   P   0   6 394   1
##   R   3  14   0 362</code></pre>
<pre class="r"><code>(390 + 380 + 393 + 364) / nrow(lettersAllTest)</code></pre>
<pre><code>## [1] 0.9801027</code></pre>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>You should find this value rather striking, for several reasons. The first is that it is significantly higher than the value for CART, highlighting the gain in accuracy that is possible from using random forest models.</p>
<p>The second is that while the accuracy of CART decreased significantly as we transitioned from the problem of predicting B or not B (a relatively simple problem) to the problem of predicting the four letters (certainly a harder problem), the accuracy of the random forest model decreased by a tiny amount.</p>
</div>
